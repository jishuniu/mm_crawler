mm_crawler
==========

一个小爬虫（原帐号1041220113）

项目需求：
1. 不要把非相关的图片也爬了；
2. 你总该考虑多线程吧？或者协程；
3. 命令行-h可以查看程序运行帮助，-n可以指定并发线程数（默认10个），-o可以指定图片存储在哪个目录（默认当前运行目录的pics目录下），-l可以限制爬多少图片就结束（默认不限制）；
4. 思考个问题，如果下次我要爬其他的美女网站，你这个程序如何尽可能利于复用；

分析：
1.分析相关美女图片的URL的特点：
 （1）通过分析网页上的图片URL地址可知，只有后缀是.jpg的图片是美女图片，gif和png等类型的图片均为非相关图片；
 （2）主页面的二级目录分布比较清晰，图片的类型分为：清凉美女，惊艳美女，美女八卦和素人美女，而首页，精选，推荐图片均来自以上目录。
    其中，清凉美女的图片URL形如："http://qlimg1.meimei22.com/pic/qingliang/2014-4-4/1/0.jpg"
          惊艳美女的图片URL形如："http://jyimg1.meimei22.com/pic/jingyan/2014-6-9/1/0.jpg"
          美女八卦的图片URL形如："http://bgimg1.meimei22.com/pic/bagua/2013-5-2/2/0.jpg"
          素人美女的图片URL形如："http://srimg1.meimei22.com/pic/suren/2012-8-17/4/0.jpg"
    其路径区别只有日期及后面的部分，二级目录的小图命名方式多为0.jpg,而它所对应的大图其URI是相同的，只是命名不同。
    如小图URL为："http://qlimg1.meimei22.com/pic/qingliang/2014-7-24/1/0.jpg"
    其对应的大图URL为："http://qlimg1.meimei22.com/pic/qingliang/2014-7-24/1/17358487320140630175250066_640.jpg"
    
2.分析页面特点
  （1）第三级页面是查看大图的页面，里面既有小图，也有大图，小图在上一级页面已经出现，为了不再重复下载，小图在这一级页面下载，大图在下级页面通过正则表达式，匹配不包含小图的路径进行下载。
  （2）首页为一级页面，清凉，惊艳，八卦和素人为二级页面（包含了所有站内图片），为了简便，我们直接对这4个页面进行操作；
  （3）三级页面的页面链接，二级页面和三级页面也都有很多下一页，这些都可以通过解析本页面的代码同时进行正则匹配得到；
  （4）为了避免下载到二级页面中的“最新推荐”栏的图片造成重复下载，需要匹配更为精确的正则表达式；
  （5）下载图片的顺序采用先下载浅层图片，再下载深层图片的原则，这样在利用多线程下载时，可尽量减少刚开始下载图片的时间；

3.抓取图片链接的特点
  （1）大图采用了防止盗链的机制，无法通过urllib简单解析得到图片链接，通过模拟浏览器获取页面内容解决这一问题；
  （2）针对程序的复用性问题，这和图片抓取的准确性是相悖的（图片的重复下载和非相关图片的下载），因此，顾及其一，从某种程度里说，势必削弱另一方。
  
实现过程：
1.完成设置命令行参数，初始化并发线程数，图片存储目录和限制爬去的图片数量；
2.完成页面链接的获取；
3.完成当前页面有效图片的获取；
4.执行下载：把下载任务托付给一个工作线程池；

实现方法：
1.分析网站结构（在过滤掉非相关图片的前提下）：根页面--二级页面（图片分类目录4个）--每个二级页面分页（根据总套图数确定，每页35套）--每个页面的套图（35张）（需爬虫）--每个套图所对应的三级页面大图（根据总大图数确定，每页1张）。总体来看，这是一个深度为5的树状结构，每层的节点数各不相同，下层节点（链接地址）需要通过上层母节点（页面代码解析）得到。
2.实现结构化编程，对树状结构进行深度优先遍历，每个节点存储页面链接，得到的最后两层链接分别存储在一个list中，分别解析这两层链接代码得到相应图片链接并托付给一个工作线程池完成下载。

完成情况：
1.已完成命令行参数的设置，并初始化各参数；
2.已完成页面链接和图片链接的获取；
3.已完成多线程下载；（下载1000张图片大概运行1000ms-2500ms,需进一步优化）
4.已完成对正则匹配的进一步修改（经过测试之后发现之前的匹配遗漏了少量图片）
5.已完成剪枝操作，在保证限制以内图片能够完全下载的情况下，及时跳出循环，减少不必要的开销。
6.调用完一个list,及时清空里面的数据，避免造成list的数据过多。


思考：
1.考虑程序在其它网站的复用，应增加首页地址输入的命令行参数；
2.尽量利用正则表达式匹配较为精确的二级菜单链接或往pageList的初始化list中append新的二级菜单链接；

后期：
1.对程序进一步优化，加快运行速度；
2.尝试基于Djongo的框架开发一个web app;
